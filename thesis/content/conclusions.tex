\section{Conclusions}
\label{sec:conclusions}

In choosing performance, expressiveness and energy use as the three metrics to measure on, the goal was to provide an environment in which any of the five languages would have the chance to stand out. In this regard the research can be considered successful: each of the five languages managed to be at least as high as the \nth{2} position in at least one metrics table.

In this thesis it has been shown that this methodology can distinguish the suitability of a programming language based on the selected metrics. When applied evenly to the set of languages being evaluated, the methodology was able to choose a clear leader. The methodology itself was demonstrated to evaluate disparate languages in a fair manner, even when some measurements were significantly disproportionate.

Additionally, the novel DFA-Gap algorithm was shown to be effective at approximate-matching while also being simple to implement. When directly compared to the use of an existing regular expression engine, it consistently performed better for the non-interpreted languages. With the distinction of its approach to defining and constraining gaps, it can be further developed as an additional tool for researchers to use.

The results of this research can be immediately put to use: Rust can be recommended for this field of computing not only for its approach to memory safety, but also on the merits of raw performance and lower energy consumption. The methodology developed and demonstrated here showed a difference of nearly 14\% between Rust and the next-lowest energy usage score.

The DFA-Gap algorithm has shown that it can be applied in cases where an edit distance-based algorithm yields unsatisfactory results. Sequence alignments can be computed with more control over the gaps between nucleotides. Researchers can choose when and whether to implement this new approach over the edit distance approach.

Presented with a larger dataset, how would these metrics change? A greater selection of source code files could lead to more precision in the expressiveness measurements, while more data points would have a similar effect on the scores for energy usage and performance. It could be possible to refine the methodology in ways that weigh the different metrics as opposed to treating them equally. The methodology might then be further refined in new ways that would allow someone to choose the weights of the various metrics based on their specific needs and goals.

Where memory safety was only briefly addressed here, additional work and research could add consideration of memory management and memory issues to the metrics. This could take the form of an additional facet of expressiveness, or even become its own metric.

Future work can also include greater analysis of and experimentation with the novel algorithm; based on the structure of the Aho-Corasick algorithm it is very possible that the novel algorithm can be extended to multiple-pattern matching, as well.

Where energy efficiency is as important as performance, this methodology has shown its ability to clearly rank languages.
